---
layout:     post
title:      "Scaling Memcache at Facebook论文读书笔记"
date:       2017-03-05 08:00:00 +0800
author:     "DongYeo"
header-img: "img/post-bg-01.jpg"
tags: ["分布式"]
---

## 前言

前一阵工作项目的编码过程中，由于数据库的读取的循环递归，造成接口请求的时间长到了令人发指的地步，sql已经没有优化的地方了，提高接口的性能。

## 更新缓存

说到缓存的更新，似乎是一件再简单不过的事情。无非是数据更新，以一定的键值丢给内存数据库。但仔细想想便会发现，这个更新的数据并不是随随便便丢给数据库这么简单的一件事情。尤其是再高并发的情况下，随随便便把跟新的数据放入缓存，很可能造成脏数据的写入。如图所示，当先后有两个请求更新同一个资源S，a请求更新为Sa，后来的请求b更新为Sb，实际数据库的数据应该是Sb才对，然后请求a由于某种原因，在请求b更新缓存后把自己更新的数据放入了缓存，造成了缓存数据的脏。

![cache-dirty-update]({{ site.baseurl }}/img/cache-dirty-update.png)

那到底如何更新缓存呢？搜索引擎的帮助下，找到了一篇facebook的论文，文中部分篇幅介绍了facebook的缓存更新逻辑。
[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)

facebook使用了一种叫做Cache Aside Pattern的缓存更新逻辑，具体逻辑如下：

- 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。

直接上图：
![facebook缓存更新策略]({{ site.baseurl }}/img/facebook-cache-update-pattern.png)

这种更新策略非常好地避免了旧的更新脏数据写入缓存。在高并发的情况下可能会造成请求数据不实时（在更新完数据未失效缓存这段时间），但也是小概率事件。

这种更新机制就万无一失了么？其实也并不是，看下图：

![读写并发造成脏数据]({{ site.baseurl }}/img/cache-read-write.png)

当缓存失效的时候，先有一个读请求，由于失效，请求持久层读取数据，读取完数据到写入缓存这段时间，另外一个请求更新了资源并失效了缓存，如此既一来，缓存中的就是旧的脏数据了。单在实际的情况下，这种事情发生的概率极低，因为一个写入的跟新操作，需要开启事务等操作，实际的时间上会比请求的时间大很多，也就是，上图的失效缓存的操作只（超大概率）会在写入缓存之后。如下图所示：

![读写并发造成脏数据]({{ site.baseurl }}/img/cache-read-write-ok.png)

## 扩展

上面提到这篇论文，笔者仔细看了一下，其中关于缓存系统降低负载的部分，非常有意思。

facebook的缓存系统引入了leases机制，来避免脏数据和并发请求对持久层的直击。

- 避免脏数据：

  当客户端访问缓存系统未命中缓存的时候，缓存服务器会给请求客户端一个leases token，回写数据到缓存的时候，服务器校验token，只有token检验通过的，才能证明这个请求是最新的读缓存miss的请求，并认定他的数据是最新的和数据库同步的数据。

- 避免高并发持久层请求

  当有缓存失效的时候，有若干的并发请求，读取同一个资源，这些请求都会去读数据库，然后请求写缓存。facebook对leases的token生成做出了一定的改进，同一个key的token的生成时间间隔是10s，这样，当有若干的请求缓存失效的时候，只有一个请求能cache miss拿到token，而其他的缓存请求将会被阻塞主，在阻塞的这段时间，唯一返回的那个请求将会读数据库，写缓存，写完缓存后阻塞的并发请求将会拿到第一个请求更新的缓存数据。

![leases]({{ site.baseurl }}/img/leases.png)
